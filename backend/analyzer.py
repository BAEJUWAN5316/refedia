import os
import json
import google.generativeai as genai
from dotenv import load_dotenv
import yt_dlp
from youtube_transcript_api import YouTubeTranscriptApi, TranscriptsDisabled, NoTranscriptFound
import base64
import io
from PIL import Image

# Load environment variables
load_dotenv()
GEMINI_API_KEY = os.getenv("GEMINI_API_KEY")

# Configure Gemini
if GEMINI_API_KEY:
    genai.configure(api_key=GEMINI_API_KEY)

# 2ë‹¨ê³„: ì¹´í…Œê³ ë¦¬ ì •ì˜
CATEGORIES_JSON = {
    "industry": ["FNB", "Home/Interior", "Shopping/Retail", "IT/Service/Auto", "Corporate/CSR", "Finance/Insurance", "Game", "Beauty/Fashion", "Health/Pharma", "Living/Kids/Pet", "Entertainment", "Leisure/Travel", "Public/Gov", "Construction/RealEstate", "Education"],
    "genre": ["Variety", "Documentary", "Fake Docu", "Survival", "Mukbang", "Review", "Dance", "Road/Street", "Info/Guide", "Experience", "Talk Show", "Podcast", "Participatory", "Branded", "Live", "Challenge", "Viral", "Sketch", "Travel", "Fandom", "Vlog", "Shorts", "Playlist", "Behind", "Reaction", "ASMR", "News/Issue"],
    "cast": ["Influencer", "Celebrity", "Comedian", "Singer", "Virtual", "Alt-Character(Bu-character)", "Expert", "General Public", "Employees/CEO", "Kids", "Pet", "Couple", "Foreigner"],
    "mood": ["Serious", "B-grade", "Humor", "Seasonal", "Meme", "Healing/Emotional", "Retro", "Luxury", "Kitsch", "Dynamic", "Motivational", "Bizarre"],
    "editing": ["Subtitle/Font", "VFX", "Infographic", "AI-Generated", "Interactive", "Motion Graphics", "Cinematic", "Typography", "Vertical", "One-take", "Chroma-key", "Fast-paced"]
}

def extract_video_data(url):
    """
    1ë‹¨ê³„: ë°ì´í„° ì¶”ì¶œ
    yt-dlpë¥¼ ì‚¬ìš©í•˜ì—¬ channel_name, video_title, video_descriptionì„ ê°€ì ¸ì˜¤ê³ ,
    youtube-transcript-apië¥¼ ì‚¬ìš©í•˜ì—¬ ìë§‰ì„ ê°€ì ¸ì˜µë‹ˆë‹¤.
    ì¶”ê°€: youtube_serviceì—ì„œ í”„ë ˆì„ê³¼ ì¸ë„¤ì¼ë„ ê°€ì ¸ì˜µë‹ˆë‹¤.
    """
    video_data = {
        "channel_name": "Unknown Channel",
        "video_title": "Unknown Title",
        "video_description": "",
        "transcript_snippet": "ìë§‰ ì—†ìŒ",
        "images_data": []
    }

    # 1. Extract Metadata using yt-dlp
    ydl_opts = {
        'quiet': True,
        'no_warnings': True,
        'extract_flat': True, # ë©”íƒ€ë°ì´í„°ë§Œ ì¶”ì¶œ
    }
    
    video_id = None
    try:
        with yt_dlp.YoutubeDL(ydl_opts) as ydl:
            info = ydl.extract_info(url, download=False)
            video_data["channel_name"] = info.get('uploader') or info.get('channel') or info.get('uploader_id')
            video_data["video_title"] = info.get('title')
            video_data["video_description"] = info.get('description')
            video_id = info.get('id')
            
            # ì¸ë„¤ì¼ URL
            thumbnail_url = info.get('thumbnail')
            
            # Import visual extraction tools from youtube_service
            try:
                from youtube_service import extract_frames, download_image_as_base64
                
                print("ğŸ–¼ï¸ Extracting visual data...")
                # ì¸ë„¤ì¼ ë‹¤ìš´ë¡œë“œ
                if thumbnail_url:
                    thumb_b64 = download_image_as_base64(thumbnail_url)
                    if thumb_b64:
                        video_data["images_data"].append(thumb_b64)
                
                # í”„ë ˆì„ ì¶”ì¶œ
                frames = extract_frames(url, count=3)
                if frames:
                    video_data["images_data"].extend(frames)
                    
            except Exception as ve:
                print(f"âš ï¸ Visual extraction failed: {ve}")

    except Exception as e:
        print(f"Error extracting metadata with yt-dlp: {e}")
        return None

    # 2. Extract Transcript using youtube-transcript-api
    if video_id:
        try:
            # í•œêµ­ì–´ ìš°ì„ , ì˜ì–´ ì°¨ì„ 
            transcript_list = YouTubeTranscriptApi.get_transcript(video_id, languages=['ko', 'en'])
            
            # ìë§‰ í…ìŠ¤íŠ¸ í•©ì¹˜ê¸°
            full_transcript = " ".join([entry['text'] for entry in transcript_list])
            
            # 500~1000ì ì œí•œ (ì—¬ê¸°ì„œëŠ” 1000ì)
            if len(full_transcript) > 1000:
                video_data["transcript_snippet"] = full_transcript[:1000] + "..."
            else:
                video_data["transcript_snippet"] = full_transcript
            
        except (TranscriptsDisabled, NoTranscriptFound):
            video_data["transcript_snippet"] = "ìë§‰ ì—†ìŒ"
        except Exception as e:
            print(f"Error extracting transcript: {e}")
            video_data["transcript_snippet"] = "ìë§‰ ì—†ìŒ (ì˜¤ë¥˜ ë°œìƒ)"

    return video_data

def analyze_video_category(video_data):
    """
    3ë‹¨ê³„: Gemini API í˜¸ì¶œ
    """
    if not GEMINI_API_KEY:
        raise ValueError("GEMINI_API_KEY is not set in .env file")

    # ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ êµ¬ì„±
    categories_str = json.dumps(CATEGORIES_JSON, ensure_ascii=False, indent=2)
    
    prompt_text = f"""
    [ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ë‚´ìš©] ë‹¹ì‹ ì€ 'REFEDIA'ë¥¼ ìœ„í•œ ì „ë¬¸ ì˜ìƒ ì½˜í…ì¸  ë¶„ì„ê°€ì…ë‹ˆë‹¤. ë‹¹ì‹ ì˜ ì„ë¬´ëŠ” ìœ íŠœë¸Œ ì˜ìƒ ë°ì´í„°ë¥¼ ë¶„ì„í•˜ì—¬ ê°€ì¥ ì ì ˆí•œ ì¹´í…Œê³ ë¦¬ë¡œ ë¶„ë¥˜í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤.

    ### 1. ì…ë ¥ ë°ì´í„°

    ì±„ë„ëª…: {video_data['channel_name']}

    ì˜ìƒ ì œëª©: {video_data['video_title']}

    ì˜ìƒ ì„¤ëª…: {video_data['video_description']}

    ì‹œê° ì •ë³´: (ì²¨ë¶€ëœ ì´ë¯¸ì§€ë“¤ì„ ì°¸ê³ í•˜ì„¸ìš”. ì¸ë„¤ì¼ ë° ì£¼ìš” ì¥ë©´ í”„ë ˆì„ì…ë‹ˆë‹¤.)

    ìë§‰ ìš”ì•½: {video_data['transcript_snippet']}

    ### 2. ì‚¬ìš© ê°€ëŠ¥í•œ ì¹´í…Œê³ ë¦¬ (JSON)
    {categories_str}

    ### 3. ë¶„ì„ ì§€ì¹¨ (ë‹¨ê³„ë³„ ì¶”ë¡  - ì¤‘ìš”!) ì¹´í…Œê³ ë¦¬ë¥¼ ì„ íƒí•˜ê¸° ì „ì—, ë‚´ë¶€ì ìœ¼ë¡œ ë‹¤ìŒ ë¶„ì„ì„ ë¨¼ì € ìˆ˜í–‰í•˜ì„¸ìš”:

    ì±„ë„ ì •ì²´ì„± íŒŒì•…: ì´ ì±„ë„ì´ ê¸°ì—…ì¸ê°€, ê°œì¸ì¸ê°€, ì•„ë‹ˆë©´ ì½”ë¯¸ë”” ì±„ë„ì¸ê°€? (ì˜ˆ: 'í”¼ì‹ëŒ€í•™' -> ì½”ë¯¸ë””)

    ì£¼ëœ ì˜ë„ ê²°ì •: ëª©ì ì´ ì¬ë¯¸(ì½”ë¯¸ë””, ì½©íŠ¸)ì¸ê°€ ì •ë³´ ì „ë‹¬(ë‰´ìŠ¤)ì¸ê°€?

    ì£¼ì˜: ë§Œì•½ ìœ ëª…í•œ ì½”ë¯¸ë”” ì±„ë„ì´ ì§„ì§€í•œ ì œëª©ì˜ ì˜ìƒ(íŒ¨ëŸ¬ë””)ì„ ì˜¬ë ¸ë‹¤ë©´, ì†ì§€ ë§ê³  ì—”í„°í…Œì¸ë¨¼íŠ¸/ì½”ë¯¸ë””ë¡œ ë¶„ë¥˜í•˜ì„¸ìš”.

    ë¶„ìœ„ê¸° ë¶„ì„: ì½˜í…ì¸ ê°€ ì§„ì§€í•œê°€, ì¬ì¹˜ ìˆëŠ”ê°€, ì˜í™” ê°™ì€ê°€? (ì²¨ë¶€ëœ ì´ë¯¸ì§€ì˜ ìƒ‰ê°, ìë§‰ ìŠ¤íƒ€ì¼, í‘œì • ë“±ì„ ì ê·¹ í™œìš©í•˜ì„¸ìš”!)

    ì¹´í…Œê³ ë¦¬ ì„ íƒ: 
    - **ì—…ì¢…(Industry)ì€ ë°˜ë“œì‹œ 1ê°œ ì´ìƒ ì„ íƒí•´ì•¼ í•©ë‹ˆë‹¤.** (ê°€ì¥ ì—°ê´€ì„± ë†’ì€ ê²ƒìœ¼ë¡œ ì¶”ë¡ )
    - ê·¸ ì™¸ í•­ëª©ë„ í•´ë‹¹ëœë‹¤ë©´ ì—¬ëŸ¬ ê°œì˜ íƒœê·¸ë¥¼ ì„ íƒí•˜ì„¸ìš”.

    ### 4. ì¶œë ¥ í˜•ì‹ ì˜¤ì§ ìœ íš¨í•œ JSON ê°ì²´ë§Œ ë°˜í™˜í•˜ì„¸ìš”. ë§ˆí¬ë‹¤ìš´(```json)ì€ ì“°ì§€ ë§ˆì„¸ìš”. {{ "industry": [...], "genre": [...], ... }}
    """

    # ì»¨í…ì¸  êµ¬ì„±
    contents = [prompt_text]
    
    if video_data.get("images_data"):
        print(f"ğŸ–¼ï¸ Processing {len(video_data['images_data'])} images for Gemini...")
        for img_str in video_data["images_data"]:
            try:
                if "base64," in img_str:
                    img_str = img_str.split("base64,")[1]
                
                image_bytes = base64.b64decode(img_str)
                image = Image.open(io.BytesIO(image_bytes))
                contents.append(image)
            except Exception as e:
                print(f"âš ï¸ Failed to process an image: {e}")

    try:
        # ëª¨ë¸: gemini-2.0-flash-lite-001 ì‚¬ìš© (ì•ˆì •ì„± ë° ì†ë„ ê³ ë ¤)
        model = genai.GenerativeModel('gemini-2.0-flash-lite-001')
        
        response = model.generate_content(contents)
        
        # ì‘ë‹µ í…ìŠ¤íŠ¸ ì •ì œ
        text = response.text.strip()
        if text.startswith("```json"):
            text = text[7:]
        if text.endswith("```"):
            text = text[:-3]
            
        return json.loads(text)

    except Exception as e:
        print(f"Gemini Analysis Failed: {e}")
        return None

if __name__ == "__main__":
    # ìƒ˜í”Œ ì½”ë“œ
    print("--- REFEDIA Video Analyzer Test ---")
    
    # ë”ë¯¸ URL (í”¼ì‹ëŒ€í•™ - í•œì‚¬ë‘ì‚°ì•…íšŒ ì˜ˆì‹œ)
    dummy_url = "https://www.youtube.com/watch?v=0tO0lTqVjXU" 
    
    print(f"Analyzing URL: {dummy_url}...")
    
    # 1. ë°ì´í„° ì¶”ì¶œ
    data = extract_video_data(dummy_url)
    
    if data:
        print("\n[Extracted Data]")
        print(f"Channel: {data['channel_name']}")
        print(f"Title: {data['video_title']}")
        print(f"Transcript (First 100 chars): {data['transcript_snippet'][:100]}...")
        
        # 2. AI ë¶„ì„
        print("\n[Analyzing with Gemini...]")
        result = analyze_video_category(data)
        
        if result:
            print("\n[Analysis Result]")
            print(json.dumps(result, indent=2, ensure_ascii=False))
        else:
            print("Analysis failed.")
    else:
        print("Failed to extract video data.")
